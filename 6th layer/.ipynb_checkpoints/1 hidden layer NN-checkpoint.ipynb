{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import pool\n",
    "import random\n",
    "\n",
    "#import input data\n",
    "neurons = scipy.io.loadmat('input_neuron')\n",
    "neuron_input = neurons['WB']\n",
    "neuron_train = neuron_input[0:80]\n",
    "neuron_test = neuron_input[80:100]\n",
    "\n",
    "force = scipy.io.loadmat('true.mat')\n",
    "data_label=np.asarray(force['skt']).reshape(-1)\n",
    "label_y=(data_label-np.mean(data_label))/np.std(data_label)\n",
    "label_train=label_y[0:80]\n",
    "label_test=label_y[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20L,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(data1, data2):\n",
    "    def shared_dataset(data1,data2,borrow=True):\n",
    "        shared_x = theano.shared(np.asarray(data1, dtype=theano.config.floatX),borrow=True)\n",
    "        shared_y = theano.shared(np.asarray(data2, dtype=theano.config.floatX),borrow=True)\n",
    "        return shared_x, T.cast(shared_y,'float64')\n",
    "    \n",
    "    train_set_x, train_set_y = shared_dataset(data1,data2)\n",
    "    rval = [(train_set_x, train_set_y)]\n",
    "    return rval\n",
    "\n",
    "class RBM_NN(object):\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        self.W = theano.shared(value=np.zeros((n_in, n_out),dtype=theano.config.floatX),name='W',borrow=True)\n",
    "        self.b = theano.shared(value=np.zeros((n_out,),dtype=theano.config.floatX),name='b',borrow=True)               \n",
    "        self.y_pred = T.dot(input, self.W)+self.b      \n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def difference(self,y):\n",
    "        return T.mean(abs(self.y_pred-T.reshape(y,[10,1])))\n",
    "    \n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out):\n",
    "        self.input = input\n",
    "        W_values = np.asarray(rng.uniform(low=-np.sqrt(6./(n_in+n_out)),\n",
    "                                          high=np.sqrt(6./(n_in+n_out)),\n",
    "                                          size=(n_in,n_out)),\n",
    "                              dtype=theano.config.floatX)\n",
    "        W = theano.shared(value=W_values, name='W',borrow=True)\n",
    "        \n",
    "        b_values = np.zeros((n_out,),dtype=theano.config.floatX)\n",
    "        b = theano.shared(value=b_values, name='b',borrow=True)\n",
    "        \n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        \n",
    "        lin_output = T.dot(input,self.W) + self.b\n",
    "        self.output = T.nnet.sigmoid(lin_output)\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "class MLP(object):\n",
    "    def __init__(self, rng,input,n_in, n_hidden, n_out):\n",
    "        self.hiddenLayer1 = HiddenLayer(rng,\n",
    "                                       input=input,\n",
    "                                       n_in=n_in,\n",
    "                                       n_out=n_hidden)\n",
    "        \n",
    "        self.LR=RBM_NN(input=self.hiddenLayer1.output,\n",
    "                      n_in=n_hidden,\n",
    "                      n_out=n_out)\n",
    "        \n",
    "        self.L2_sqr = ((self.hiddenLayer1.W**2).sum()+\n",
    "                       (self.LR.W**2).sum()\n",
    "                      )\n",
    "        \n",
    "        \n",
    "        self.error = (self.LR.difference)\n",
    "        \n",
    "        self.params = self.hiddenLayer1.params + self.LR.params\n",
    "        \n",
    "        self.input = input\n",
    "\n",
    "        \n",
    "def test_mlp(learning_rate=0.01, n_epochs=2000,  data1=neuron_train, data2=label_train,\n",
    "             data3=neuron_test, data4=label_test, batch_size=10, n_hidden=1000):\n",
    "    datasets_train = load_data(data1,data2)\n",
    "    datasets_test = load_data(data3,data4)\n",
    "    \n",
    "    train_set_x, train_set_y = datasets_train[0]\n",
    "    test_set_x, test_set_y = datasets_test[0]\n",
    "    \n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    n_test_batches = test_set_x.get_value(borrow=True).shape[0]//batch_size\n",
    "    \n",
    "    ######################\n",
    "    # BUILD ACTUAL MODEL #\n",
    "    ######################\n",
    "    print('... building the model')\n",
    "    index = T.lscalar()\n",
    "    x = T.matrix('x')\n",
    "    y = T.vector('y')    \n",
    "    \n",
    "    rng = np.random.RandomState(1234)\n",
    "    \n",
    "    classifier = MLP(rng=rng,\n",
    "                    input=x,\n",
    "                    n_in=200*200,\n",
    "                    n_hidden=n_hidden,\n",
    "                    n_out=1)\n",
    "    \n",
    "    cost=(classifier.error(y)+0.0001*classifier.L2_sqr)\n",
    "    \n",
    "    test_model = theano.function(inputs=[index],\n",
    "                                outputs=classifier.error(y),\n",
    "                                givens={\n",
    "            x:test_set_x[index*batch_size:(index+1)*batch_size],\n",
    "            y:test_set_y[index*batch_size:(index+1)*batch_size]\n",
    "        })\n",
    "    \n",
    "    gparams = [T.grad(cost,param) for param in classifier.params]\n",
    "    \n",
    "    updates = [(param, param - learning_rate*gparam) for \n",
    "              param, gparam in zip(classifier.params, gparams)]\n",
    "    \n",
    "    train_model = theano.function(inputs=[index],\n",
    "                                 outputs=cost,\n",
    "                                 updates=updates,\n",
    "                                 givens={\n",
    "            x: train_set_x[index*batch_size:(index+1)*batch_size],\n",
    "            y: train_set_y[index*batch_size:(index+1)*batch_size]\n",
    "        })\n",
    "\n",
    "    ###############\n",
    "    # TRAIN MODEL #\n",
    "    ###############\n",
    "    print('... training the model')\n",
    "    \n",
    "    epoch=0 \n",
    "    while (epoch<n_epochs):\n",
    "        epoch = epoch + 1\n",
    "        #print epoch\n",
    "        #if epoch != 1:\n",
    "        #    W=test_mlp2()\n",
    "            \n",
    "        for minibatch_index in range(n_train_batches): \n",
    "            minibatch_avg_cost=train_model(minibatch_index)    \n",
    "            # iteration number\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "            #print iter\n",
    "            if (iter + 1) % 8 == 0:\n",
    "                # compute zero-one loss on validation set\n",
    "                losses = [train_model(i) for i in range(n_train_batches)]\n",
    "                this_loss = np.mean(losses)\n",
    "                \n",
    "                print \"Epoch {0}, Minibatch {1}/{2}, Test Error= {3}\".format(epoch,minibatch_index+1,n_train_batches,\n",
    "                                                                       this_loss)\n",
    "\n",
    "        if epoch%10==0:\n",
    "            test_losses = [test_model(i) for i in range(n_test_batches)]\n",
    "            print test_losses\n",
    "            test_score = np.mean(test_losses)\n",
    "            \n",
    "            print \"Testing Score= {0}\".format(test_score)\n",
    "            \n",
    "            \n",
    "    return classifier.params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "... training the model\n",
      "Epoch 1, Minibatch 4/8, Test Error= 1.1628492415\n",
      "Epoch 1, Minibatch 8/8, Test Error= 0.926821408647\n",
      "Epoch 2, Minibatch 4/8, Test Error= 0.904760118008\n",
      "Epoch 2, Minibatch 8/8, Test Error= 0.899338262267\n",
      "[array(0.8623016624210667), array(0.9817068274057889)]\n",
      "Testing Score= 0.922004244913\n",
      "Epoch 3, Minibatch 4/8, Test Error= 0.864867503351\n",
      "Epoch 3, Minibatch 8/8, Test Error= 0.966189012209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-0aa3909280f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_mlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-96a086a4290e>\u001b[0m in \u001b[0;36mtest_mlp\u001b[1;34m(learning_rate, n_epochs, data1, data2, data3, data4, batch_size, n_hidden)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mminibatch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mminibatch_avg_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[1;31m# iteration number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_train_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mminibatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\tensor\\blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out)\u001b[0m\n\u001b[0;32m   1550\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m             \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1553\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \u001b[1;31m# The error raised by numpy has no shape information, we mean to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W=test_mlp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
